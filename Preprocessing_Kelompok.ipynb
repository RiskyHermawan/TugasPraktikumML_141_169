{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing Kelompok.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM48gipA1jdj7s+PFXx5Rih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiskyHermawan/TugasPraktikumML_141_169/blob/main/Preprocessing_Kelompok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKVP6GnL_pNb"
      },
      "source": [
        "# Input Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNmtEIOKAbgc",
        "outputId": "352a0c9e-f7bf-4b61-c153-92971a32f338"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sklzkKgyCT-v",
        "outputId": "6d675e27-17d7-40e4-c4a6-566fd0f3c601"
      },
      "source": [
        "# masuk ke directory penyimpanan dataset anda\n",
        "%cd /content/drive/MyDrive/Semester7/MachineLearning7D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Semester7/MachineLearning7D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLh98hE3ydOt",
        "outputId": "9563bebf-3800-4167-f603-947da72839d9"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " flowers\t\t\t  model_cell_flowers\n",
            " Flowers_Recognition.zip\t 'Perceptron (build from scratch).ipynb'\n",
            "'Literatur Review 141_169.docx'  'WAML – Perceptron – 201810370311141.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TazqzKcWCT7c"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'Flowers_Recognition.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/drive/MyDrive/Semester7/MachineLearning7D') #mengeksrak file zip ke direktory yang sudah ditentukan\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyBZSgtGCT2M"
      },
      "source": [
        "import os\n",
        "base_dataset = ('/content/drive/MyDrive/Semester7/MachineLearning7D/flowers') #letak file gambar di direktori\n",
        "class_dir = ['daisy','dandelion','rose','sunflower','tulip'] #ada 5 jenis \n",
        "for class_item in class_dir:\n",
        "  cur_dir = base_dataset+\"/\"+class_item\n",
        "  dataset = os.listdir(cur_dir)\n",
        "  for item in dataset:\n",
        "    if not item.endswith(\".jpg\"):\n",
        "        os.remove(os.path.join(cur_dir, item)) #menghilangkan file selain berformat jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHodBlQV_0Sr"
      },
      "source": [
        "# Splitting data 70% 30%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaZY7lMY_8nb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ceea11ba-77ec-4d07-a0ed-8de5696a939c"
      },
      "source": [
        "#membuat folder baru model_cell_images\n",
        "from os import mkdir\n",
        "\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5741059ea9d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "UKM53u4czaRA",
        "outputId": "f62a096b-ad4b-4017-b344-1af8df882f88"
      },
      "source": [
        "#membuat 2 folder baru di dalam folder model_cell_images\n",
        "from os import mkdir\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6f4ff1ee098a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#membuat 2 folder baru di dalam folder model_cell_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PljI98HNzkL4"
      },
      "source": [
        "#membuat folder baru kelas paratized di kedua folder diatas\n",
        "from os import mkdir\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/daisy')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/dandelion')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/rose')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/sunflower')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/tulip')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/daisy')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/dandelion')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/rose')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/sunflower')\n",
        "mkdir('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/tulip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs11MHQUzBxs"
      },
      "source": [
        "#Splitting dataset \"daisy\" yaitu dengan membuat folder gambar untuk memisahkan gambar tersebut 70% sebagai data training dan 30% sebagai data testing\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "daisy_original = \"/content/drive/MyDrive/Semester7/MachineLearning7D/flowers/daisy\"\n",
        "daisy_train = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/daisy\"\n",
        "daisy_validation = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/daisy\"\n",
        "\n",
        "filesdaisy = os.listdir(daisy_original)\n",
        "\n",
        "# memindahkan 70% file\n",
        "for file in filesdaisy[0:int(len(filesdaisy) * .7)]:\n",
        "  new_path = shutil.move(f\"{daisy_original}/{file}\", daisy_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7viRlKMzZ1g"
      },
      "source": [
        "filesdaisy2 = os.listdir(daisy_original)\n",
        "\n",
        "# memmindahkan sisa(seluruh file)\n",
        "for file in filesdaisy2:\n",
        "    new_path = shutil.move(f\"{daisy_original}/{file}\", daisy_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S38D1BY_z9_G"
      },
      "source": [
        "#Splitting dataset \"dandelion\" yaitu dengan membuat folder gambar untuk memisahkan gambar tersebut 70% sebagai data training dan 30% sebagai data testing\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dandelion_original = \"/content/drive/MyDrive/Semester7/MachineLearning7D/flowers/dandelion\"\n",
        "dandelion_train = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/dandelion\"\n",
        "dandelion_validation = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/dandelion\"\n",
        "\n",
        "filesdandelion = os.listdir(dandelion_original)\n",
        "\n",
        "# memindahkan 70% file\n",
        "for file in filesdandelion[0:int(len(filesdandelion) * .7)]:\n",
        "  new_path = shutil.move(f\"{dandelion_original}/{file}\", dandelion_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1GfVAWG0_Cz"
      },
      "source": [
        "filesdandelion2 = os.listdir(dandelion_original)\n",
        "\n",
        "# memmindahkan sisa(seluruh file)\n",
        "for file in filesdandelion2:\n",
        "    new_path = shutil.move(f\"{dandelion_original}/{file}\", dandelion_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaqsBPCX1sNp"
      },
      "source": [
        "#Splitting dataset \"rose\" yaitu dengan membuat folder gambar untuk memisahkan gambar tersebut 70% sebagai data training dan 30% sebagai data testing\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "rose_original = \"/content/drive/MyDrive/Semester7/MachineLearning7D/flowers/rose\"\n",
        "rose_train = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/rose\"\n",
        "rose_validation = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/rose\"\n",
        "\n",
        "filesrose = os.listdir(rose_original)\n",
        "\n",
        "# memindahkan 70% file\n",
        "for file in filesrose[0:int(len(filesrose) * .7)]:\n",
        "  new_path = shutil.move(f\"{rose_original}/{file}\", rose_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7f4hukT1t_I"
      },
      "source": [
        "filesrose2 = os.listdir(rose_original)\n",
        "\n",
        "# memmindahkan sisa(seluruh file)\n",
        "for file in filesrose2:\n",
        "    new_path = shutil.move(f\"{rose_original}/{file}\", rose_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMOnciKF2VdG"
      },
      "source": [
        "#Splitting dataset \"sunflower\" yaitu dengan membuat folder gambar untuk memisahkan gambar tersebut 70% sebagai data training dan 30% sebagai data testing\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "sunflower_original = \"/content/drive/MyDrive/Semester7/MachineLearning7D/flowers/sunflower\"\n",
        "sunflower_train = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/sunflower\"\n",
        "sunflower_validation = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/sunflower\"\n",
        "\n",
        "filessunflower = os.listdir(sunflower_original)\n",
        "\n",
        "# memindahkan 70% file\n",
        "for file in filessunflower[0:int(len(filessunflower) * .7)]:\n",
        "  new_path = shutil.move(f\"{sunflower_original}/{file}\", sunflower_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficT0z5l2WMH"
      },
      "source": [
        "filessunflower2 = os.listdir(sunflower_original)\n",
        "\n",
        "# memmindahkan sisa(seluruh file)\n",
        "for file in filessunflower2:\n",
        "    new_path = shutil.move(f\"{sunflower_original}/{file}\", sunflower_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkGWnZUj2WFu"
      },
      "source": [
        "#Splitting dataset \"tulip\" yaitu dengan membuat folder gambar untuk memisahkan gambar tersebut 70% sebagai data training dan 30% sebagai data testing\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "tulip_original = \"/content/drive/MyDrive/Semester7/MachineLearning7D/flowers/tulip\"\n",
        "tulip_train = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training/tulip\"\n",
        "tulip_validation = \"/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation/tulip\"\n",
        "\n",
        "filestulip = os.listdir(tulip_original)\n",
        "\n",
        "# memindahkan 70% file\n",
        "for file in filestulip[0:int(len(filestulip) * .7)]:\n",
        "  new_path = shutil.move(f\"{tulip_original}/{file}\", tulip_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVE0N0a92V9V"
      },
      "source": [
        "filestulip2 = os.listdir(tulip_original)\n",
        "\n",
        "# memmindahkan sisa(seluruh file)\n",
        "for file in filestulip2:\n",
        "    new_path = shutil.move(f\"{tulip_original}/{file}\", tulip_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a8z3WOX4KFQ",
        "outputId": "5df1a5bc-5a2b-4429-ca9e-fe82bc804215"
      },
      "source": [
        "#Cek penamaan image dan tampilkan jumlah gambar dari hasil splitting dari masing-masing kelas\n",
        "\n",
        "file_train_daisy = os.listdir(daisy_train)\n",
        "file_Val_daisy = os.listdir(daisy_validation)\n",
        "file_train_dandelion = os.listdir(dandelion_train)\n",
        "file_Val_dandelion = os.listdir(dandelion_validation)\n",
        "file_train_rose = os.listdir(rose_train)\n",
        "file_Val_rose = os.listdir(rose_validation)\n",
        "file_train_sunflower = os.listdir(sunflower_train)\n",
        "file_Val_sunflower = os.listdir(sunflower_validation)\n",
        "file_train_tulip = os.listdir(tulip_train)\n",
        "file_Val_tulip = os.listdir(tulip_validation)\n",
        "\n",
        "print(file_train_daisy[0:int(len(file_train_daisy) * .001)])\n",
        "print(\"data daisy train : \" + str(len(file_train_daisy)))\n",
        "print(\"data daisy validation : \" + str(len(file_Val_daisy)))\n",
        "print(\"data dandelion train : \" + str(len(file_train_dandelion)))\n",
        "print(\"data dandelion validation : \" + str(len(file_Val_dandelion)))\n",
        "print(\"data rose train : \" + str(len(file_train_rose)))\n",
        "print(\"data rose validation : \" + str(len(file_Val_rose)))\n",
        "print(\"data sunflower train : \" + str(len(file_train_sunflower)))\n",
        "print(\"data sunflower validation : \" + str(len(file_Val_sunflower)))\n",
        "print(\"data tulip train : \" + str(len(file_train_tulip)))\n",
        "print(\"data tulip validation : \" + str(len(file_Val_tulip)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "data daisy train : 534\n",
            "data daisy validation : 230\n",
            "data dandelion train : 736\n",
            "data dandelion validation : 316\n",
            "data rose train : 548\n",
            "data rose validation : 236\n",
            "data sunflower train : 513\n",
            "data sunflower validation : 220\n",
            "data tulip train : 688\n",
            "data tulip validation : 296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KK2VyC_59iz"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN2VPaPQ6Bxo"
      },
      "source": [
        "#Gather data training dengan ukuran gambar 100 x 100\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Gather data train inisialisasi kosongan\n",
        "train_data = []\n",
        "train_label = []\n",
        "\n",
        "train_dir=os.path.join('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/training')\n",
        "for r, d, f in os.walk(train_dir):\n",
        "    for file in f:\n",
        "        if \".jpg\" in file:\n",
        "            imagePath = os.path.join(r, file)\n",
        "            image = cv2.imread(imagePath)\n",
        "            image = cv2.resize(image, (100,100))\n",
        "            train_data.append(image)\n",
        "            label = imagePath.split(os.path.sep)[-2]\n",
        "            train_label.append(label)\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_label = np.array(train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_e_7YZ_6omm"
      },
      "source": [
        "#Gather data validation dengan ukuran gambar 100 x 100\n",
        "\n",
        "val_data = []\n",
        "val_label = []\n",
        "\n",
        "vali_dir=os.path.join('/content/drive/MyDrive/Semester7/MachineLearning7D/model_cell_flowers/validation')\n",
        "for r, d, f in os.walk(vali_dir):\n",
        "    for file in f:\n",
        "        if \".jpg\" in file:\n",
        "            imagePath = os.path.join(r, file)\n",
        "            image = cv2.imread(imagePath)\n",
        "            image = cv2.resize(image, (100,100))\n",
        "            val_data.append(image)\n",
        "            label = imagePath.split(os.path.sep)[-2]\n",
        "            val_label.append(label)\n",
        "\n",
        "val_data = np.array(val_data)\n",
        "val_label = np.array(val_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0TEIaT7dTk",
        "outputId": "bdb88bc4-8468-4a9a-f6d7-d9ea6d632b2e"
      },
      "source": [
        "#Tampilkan shape dari data train dan data validation\n",
        "\n",
        "print(\"Train Data = \", train_data.shape)\n",
        "print(\"Train Label = \", train_label.shape)\n",
        "print(\"Validation Data = \", val_data.shape)\n",
        "print(\"Validation Label = \", val_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data =  (3019, 100, 100, 3)\n",
            "Train Label =  (3019,)\n",
            "Validation Data =  (1298, 100, 100, 3)\n",
            "Validation Label =  (1298,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1NpBRf_7gK0",
        "outputId": "b1b973fe-1d92-4f59-d595-18a8f78e657b"
      },
      "source": [
        "# Normalisasi dataset\n",
        "\n",
        "print(\"Data sebelum di-normalisasi \", train_data[0][0][0])\n",
        "x_train = train_data.astype('float32') / 255.0\n",
        "x_val = val_data.astype('float32') / 255.0\n",
        "print(\"Data setelah di-normalisasi \", x_train[0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data sebelum di-normalisasi  [136 137 137]\n",
            "Data setelah di-normalisasi  [0.53333336 0.5372549  0.5372549 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohrRfwIP7iPd",
        "outputId": "b9f57576-3d42-4693-f724-3847114860c2"
      },
      "source": [
        "# membuat dan menampilkan hasil dari label encoder\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "print(\"Label sebelum di-encoder \", train_label[995:1005])\n",
        "\n",
        "lb = LabelEncoder()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_val = lb.fit_transform(val_label)\n",
        "\n",
        "print(\"Label setelah di-encoder \", y_train[995:1005])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label sebelum di-encoder  ['dandelion' 'dandelion' 'dandelion' 'dandelion' 'dandelion' 'dandelion'\n",
            " 'dandelion' 'dandelion' 'dandelion' 'dandelion']\n",
            "Label setelah di-encoder  [1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibXrXkZs_89c"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzOdQuX6AAit"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
